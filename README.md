---
title: pythonçˆ¬å–å·å»–è€å¸ˆçš„Javaæ•™ç¨‹
date: 2020-03-01 23:40:56
tags: 
- çˆ¬è™«
- python
---

    ä»Šå¤©æƒ³å­¦ç‚¹Javaï¼Œè®¿é—®äº†ä¸€ä¸‹å»–è€å¸ˆçš„ç½‘ç«™ï¼Œç»“æœç½‘å¾ˆå¡ï¼Œå¯èƒ½å»–è€å¸ˆåœ¨æ›´æ–°ç½‘ç«™ï¼Œç„¶åçªç„¶æƒ³åˆ°å¯ä»¥å†™ä¸ªçˆ¬è™«ä¸€åŠ³æ°¸é€¸ã€‚åšè¿™ä¸ªçˆ¬è™«çš„ç›®çš„ä¹Ÿæ˜¯æ–¹ä¾¿å­¦ä¹ å»–é›ªå³°è€å¸ˆçš„Javaæ•™ç¨‹ï¼Œæ¯•ç«ŸæŠŠç½‘é¡µå­˜åœ¨æœ¬åœ°æ–¹ä¾¿æµè§ˆï¼Œå¹¶æ— ä»–æ„ã€‚
<!--more-->
# Code
ç”¨çš„æ˜¯requerstå’Œxpathï¼Œæ¨èç”¨Chromeä¸Šçš„xpath helperï¼ŒçœŸé¦™ã€‚
```python
##å¯¼å…¥åº“
import os
import time
import requests
import lxml
from lxml import etree
```
## å‘é€è¯·æ±‚
```python
#send request
def send_request(url, headers):
    r = requests.get(url,headers=headers)
    print('çŠ¶æ€ç :',r.status_code)
    return r
```
## æå–æ•°æ®
```python
#fetch data
def fetch(domain,resp, headers):
    selector = lxml.etree.HTML(resp.text)    #generate object
    titles = selector.xpath('//a[@class="x-wiki-index-item"]/text()')#æ‹¿åˆ°å„ä¸ªé¡µé¢çš„å°æ ‡é¢˜ï¼Œæ¯”å¦‚ã€Šé¢å‘å¯¹è±¡ã€‹è¿™ç§      
    uri = selector.xpath('//a[@class="x-wiki-index-item"]/@href') #æ‹¿åˆ°å„ä¸ªé¡µé¢çš„urlçš„å‚æ•°
    #æ‰“åŒ…åˆ°ä¸€èµ·è¿”å›      
    urls = []
    for i in uri:
        urls.append(domain + i)    
    return titles, urls
```

## ä¸‹è½½é¡µé¢
```python
def download(titles,urls):
    #è®¾ç½®ä¸‹è½½è·¯å¾„
    cwd=os.getcwd()
    if not os.path.exists(cwd + '/å»–é›ªå³°Javaæ•™ç¨‹HTML'):
        os.mkdir(cwd + '/å»–é›ªå³°Javaæ•™ç¨‹HTML')
    filepath = cwd + '/å»–é›ªå³°Javaæ•™ç¨‹HTML/'

    for key, value in zip(titles, urls):
        resp = requests.get(value,headers=headers)
        selector = lxml.etree.HTML(resp.text)    
        #æ‹¿åˆ°å„ä¸ªé¡µé¢çš„æ­£æ–‡
        html = selector.xpath('//div[@class="uk-flex-item-1"]') 
        #è½¬æ¢ç±»å‹
        html = etree.tostring(html[0], pretty_print = True, method = "html")
        #è®¾ç½®æ–‡ä»¶å
        filename = filepath + "%d" % titles.index(key) + key +'.html'
        with open(filename,'wb')as f:
            f.write(html)
        #åŠ ä¸€ä¸ªå»¶æ—¶ï¼Œåˆ«è®¿é—®å¤ªå¿«
        time.sleep(0.3)
    print("ä¸‹è½½å®Œæˆ")
```
## ä¸»å‡½æ•°
```python
#main
headers = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chro'
                      'me/53.0.2785.104 Safari/537.36 Core/1.53.2372.400 QQBrowser/9.5.10548.400'
}
domain = 'http://www.liaoxuefeng.com'           #å»–é›ªå³°ç½‘ç«™çš„åŸŸå
url =  "https://www.liaoxuefeng.com/wiki/1252599548343744" #Javaæ•™ç¨‹çš„url

#è·å–Javaæ•™ç¨‹çš„é¡µé¢
resp = send_request(url, headers)
#æå–æ‰€æœ‰çš„æ•°æ®å›æ¥ï¼ŒåŒ…æ‹¬æ ‡é¢˜å’Œurls
titles, urls = fetch(domain, resp, headers)
#å¼€å§‹ä¸‹è½½
download(titles,urls)
```

- æ¬¢è¿pull requests~ä¸€èµ·å­¦ä¹ ğŸ˜„
